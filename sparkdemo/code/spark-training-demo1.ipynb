{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mbpmbeesley2.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data = sc.parallelize([1, \"Alice\", 50])\n",
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'Alice']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'Alice', 50]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can not infer schema for type: <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-23cbea6669d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msamplingRatio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.4/libexec/python/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_schema\u001b[0;34m(row, names)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_infer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not infer schema for type: <class 'int'>"
     ]
    }
   ],
   "source": [
    "df = simple_data.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[9] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = sc.parallelize([[1,\"Alice\", 50], [2, \"Bob\", 80]])\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Alice', 50], [2, 'Bob', 80]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'Alice', 50]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'Alice', 50], [2, 'Bob', 80]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = records.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _2: string, _3: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+\n",
      "| _1|   _2| _3|\n",
      "+---+-----+---+\n",
      "|  1|Alice| 50|\n",
      "|  2|  Bob| 80|\n",
      "+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[28] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([Row(id=1, \n",
    "                            name=\"Alice\", \n",
    "                            score=50)])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='Alice', score=50)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| id| name|score|\n",
      "+---+-----+-----+\n",
      "|  1|Alice|   50|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([Row(id = 1,\n",
    "                          name=\"Alice\",\n",
    "                          score = 50),\n",
    "                      Row(id = 2,\n",
    "                         name=\"Bob\",\n",
    "                         score = 80),\n",
    "                      Row(id = 3,\n",
    "                         name = \"Charlee\",\n",
    "                         score = 75)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| id|   name|score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charlee|   75|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(col_float=1.44,\n",
    "                                  col_integer=10,\n",
    "                                  col_string=\"John\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+\n",
      "|col_float|col_integer|col_string|\n",
      "+---------+-----------+----------+\n",
      "|     1.44|         10|      John|\n",
      "+---------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(col_float=1.44,\n",
    "                                  col_integer=10,\n",
    "                                  col_string=\"John\",\n",
    "                                  col_list=[1,2,3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---------+----------+\n",
      "|col_float|col_integer| col_list|col_string|\n",
      "+---------+-----------+---------+----------+\n",
      "|     1.44|         10|[1, 2, 3]|      John|\n",
      "+---------+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = sc.parallelize([Row(col_list=[1,2,3],\n",
    "                                  col_dict={\"k1\": 0},\n",
    "                                  col_row=Row(a=10, b=20, c=30),\n",
    "                                  col_time=datetime(2020, 1, 22, 14, 1, 5),\n",
    "                              ),\n",
    "                              Row(col_list=[4,5,6],\n",
    "                                 col_dict={\"k1\": 0, \"k2\": 1},\n",
    "                                 col_row=Row(a=40, b=50, c=60),\n",
    "                                 col_time=datetime(2020, 1, 23, 14, 1, 5)\n",
    "                             ), \n",
    "                              Row(col_list=[7,8,9],\n",
    "                                 col_dict={\"k1\":0, \"k2\":1, \"k3\":2},\n",
    "                                 col_row=Row(a=70, b=80, c=90),\n",
    "                                 col_time=datetime(2020, 1, 24, 14, 1, 5))\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+-------------------+\n",
      "|            col_dict| col_list|     col_row|           col_time|\n",
      "+--------------------+---------+------------+-------------------+\n",
      "|           [k1 -> 0]|[1, 2, 3]|[10, 20, 30]|2020-01-22 14:01:05|\n",
      "|  [k1 -> 0, k2 -> 1]|[4, 5, 6]|[40, 50, 60]|2020-01-23 14:01:05|\n",
      "|[k3 -> 2, k1 -> 0...|[7, 8, 9]|[70, 80, 90]|2020-01-24 14:01:05|\n",
      "+--------------------+---------+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df = complex_data.toDF()\n",
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x10cd41fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sqlcontext.range(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.parallelize([Row(\"Alice\", 50), \n",
    "       Row(\"Bob\", 80), \n",
    "       Row(\"Charlee\", 75)])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|     _1| _2|\n",
      "+-------+---+\n",
      "|  Alice| 50|\n",
      "|    Bob| 80|\n",
      "|Charlee| 75|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlcontext.createDataFrame(data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|score|\n",
      "+-------+-----+\n",
      "|  Alice|   50|\n",
      "|    Bob|   80|\n",
      "|Charlee|   75|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlcontext.createDataFrame(data, [\"name\", \"score\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[80] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data = sc.parallelize([Row(\n",
    "    col_string=\"Alice\",\n",
    "    col_list=[1,2,3],\n",
    "    col_dict={\"k1\": 0},\n",
    "    col_row=Row(a=10, b=20, c=30),\n",
    "    col_time=datetime(2020, 1, 22, 14, 1, 5),\n",
    "    col_integer=10,\n",
    "    col_float=1.44,\n",
    "    col_bool=True\n",
    "),\n",
    "Row(\n",
    "    col_string=\"Bob\",\n",
    "    col_list=[4,5,6],\n",
    "    col_dict={\"k1\": 0, \"k2\": 1},\n",
    "    col_row=Row(a=40, b=50, c=60),\n",
    "    col_time=datetime(2020, 1, 23, 14, 1, 5),\n",
    "    col_integer=20,\n",
    "    col_float=2.44,\n",
    "    col_bool=True\n",
    "), \n",
    "Row(\n",
    "    col_string=\"Charlee\",\n",
    "    col_list=[7,8,9],\n",
    "    col_dict={\"k1\":0, \"k2\":1, \"k3\":2},\n",
    "    col_row=Row(a=70, b=80, c=90),\n",
    "    col_time=datetime(2020, 1, 24, 14, 1, 5),\n",
    "    col_integer=30,\n",
    "    col_float=3.44,\n",
    "    col_bool=False\n",
    ")\n",
    "])\n",
    "complex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+-------------------+\n",
      "|            col_dict| col_list|     col_row|           col_time|\n",
      "+--------------------+---------+------------+-------------------+\n",
      "|           [k1 -> 0]|[1, 2, 3]|[10, 20, 30]|2020-01-22 14:01:05|\n",
      "|  [k1 -> 0, k2 -> 1]|[4, 5, 6]|[40, 50, 60]|2020-01-23 14:01:05|\n",
      "|[k3 -> 2, k1 -> 0...|[7, 8, 9]|[70, 80, 90]|2020-01-24 14:01:05|\n",
      "+--------------------+---------+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlcontext.createDataFrame(complex_data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize([\n",
    "    Row(1, \"Alice\", 50),\n",
    "    Row(2, \"Bob\", 80),\n",
    "    Row(3, \"Charlee\", 75)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = Row('id', 'name', 'score')\n",
    "students = data.map(lambda r: column_name(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='Alice', score=50),\n",
       " Row(id=2, name='Bob', score=80),\n",
       " Row(id=3, name='Charlee', score=75)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, score: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df = sqlcontext.createDataFrame(students)\n",
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| id|   name|score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charlee|   75|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[col_bool: boolean, col_dict: map<string,bigint>, col_float: double, col_integer: bigint, col_list: array<bigint>, col_row: struct<a:bigint,b:bigint,c:bigint>, col_string: string, col_time: timestamp]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data_df = sqlcontext.createDataFrame(complex_data)\n",
    "complex_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(col_dict={'k1': 0}, col_list=[1, 2, 3], col_row=Row(a=10, b=20, c=30), col_string='Alice', col_time=datetime.datetime(2020, 1, 22, 14, 1, 5))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(col_dict={'k1': 0}, col_list=[1, 2, 3], col_row=Row(a=10, b=20, c=30), col_string='Alice', col_time=datetime.datetime(2020, 1, 22, 14, 1, 5)),\n",
       " Row(col_dict={'k1': 0, 'k2': 1}, col_list=[4, 5, 6], col_row=Row(a=40, b=50, c=60), col_string='Bob', col_time=datetime.datetime(2020, 1, 23, 14, 1, 5))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_list = complex_data_df.collect()[0][1]\n",
    "cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_list.append(100)\n",
    "cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------+-------------------+\n",
      "|            col_dict| col_list|     col_row|           col_time|\n",
      "+--------------------+---------+------------+-------------------+\n",
      "|           [k1 -> 0]|[1, 2, 3]|[10, 20, 30]|2020-01-22 14:01:05|\n",
      "|  [k1 -> 0, k2 -> 1]|[4, 5, 6]|[40, 50, 60]|2020-01-23 14:01:05|\n",
      "|[k3 -> 2, k1 -> 0...|[7, 8, 9]|[70, 80, 90]|2020-01-24 14:01:05|\n",
      "+--------------------+---------+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2020, 1, 22, 14, 1, 5), {'k1': 0}),\n",
       " (datetime.datetime(2020, 1, 23, 14, 1, 5), {'k1': 0, 'k2': 1}),\n",
       " (datetime.datetime(2020, 1, 24, 14, 1, 5), {'k3': 2, 'k1': 0, 'k2': 1})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data_df.rdd\\\n",
    "                .map(lambda x: (x.col_time, x.col_dict))\\\n",
    "                .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|     col_row| col_list|\n",
      "+------------+---------+\n",
      "|[10, 20, 30]|[1, 2, 3]|\n",
      "|[40, 50, 60]|[4, 5, 6]|\n",
      "|[70, 80, 90]|[7, 8, 9]|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.select(\n",
    "    'col_row',\n",
    "    'col_list'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice Boo', 'Bob Boo', 'Charlee Boo']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_data_df.rdd\\\n",
    "    .map(lambda x: (x.col_string + \" Boo\"))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------+\n",
      "|col_integer|col_float|col_sum|\n",
      "+-----------+---------+-------+\n",
      "|         10|     1.44|  11.44|\n",
      "|         20|     2.44|  22.44|\n",
      "|         30|     3.44|  33.44|\n",
      "+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.select(\n",
    "        'col_integer',\n",
    "        'col_float'\n",
    "    )\\\n",
    "    .withColumn(\n",
    "        \"col_sum\",\n",
    "        complex_data_df.col_integer + complex_data_df.col_float\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|col_bool|col_opposite|\n",
      "+--------+------------+\n",
      "|    true|       false|\n",
      "|    true|       false|\n",
      "|   false|        true|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.select('col_bool')\\\n",
    "    .withColumn(\n",
    "        \"col_opposite\",\n",
    "        complex_data_df.col_bool == False\n",
    "    )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------+-----------+---------+------------+----------+-------------------+\n",
      "|col_bool|             col_map|col_float|col_integer| col_list|     col_row|col_string|           col_time|\n",
      "+--------+--------------------+---------+-----------+---------+------------+----------+-------------------+\n",
      "|    true|           [k1 -> 0]|     1.44|         10|[1, 2, 3]|[10, 20, 30]|     Alice|2020-01-22 14:01:05|\n",
      "|    true|  [k1 -> 0, k2 -> 1]|     2.44|         20|[4, 5, 6]|[40, 50, 60]|       Bob|2020-01-23 14:01:05|\n",
      "|   false|[k3 -> 2, k1 -> 0...|     3.44|         30|[7, 8, 9]|[70, 80, 90]|   Charlee|2020-01-24 14:01:05|\n",
      "+--------+--------------------+---------+-----------+---------+------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.withColumnRenamed(\"col_dict\", \"col_map\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|  Alice|\n",
      "|    Bob|\n",
      "|Charlee|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_data_df.select(complex_data_df.col_string.alias(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_bool</th>\n",
       "      <th>col_dict</th>\n",
       "      <th>col_float</th>\n",
       "      <th>col_integer</th>\n",
       "      <th>col_list</th>\n",
       "      <th>col_row</th>\n",
       "      <th>col_string</th>\n",
       "      <th>col_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'k1': 0}</td>\n",
       "      <td>1.44</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>(10, 20, 30)</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2020-01-22 14:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'k1': 0, 'k2': 1}</td>\n",
       "      <td>2.44</td>\n",
       "      <td>20</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>(40, 50, 60)</td>\n",
       "      <td>Bob</td>\n",
       "      <td>2020-01-23 14:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'k3': 2, 'k1': 0, 'k2': 1}</td>\n",
       "      <td>3.44</td>\n",
       "      <td>30</td>\n",
       "      <td>[7, 8, 9]</td>\n",
       "      <td>(70, 80, 90)</td>\n",
       "      <td>Charlee</td>\n",
       "      <td>2020-01-24 14:01:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_bool                     col_dict  col_float  col_integer   col_list  \\\n",
       "0      True                    {'k1': 0}       1.44           10  [1, 2, 3]   \n",
       "1      True           {'k1': 0, 'k2': 1}       2.44           20  [4, 5, 6]   \n",
       "2     False  {'k3': 2, 'k1': 0, 'k2': 1}       3.44           30  [7, 8, 9]   \n",
       "\n",
       "        col_row col_string            col_time  \n",
       "0  (10, 20, 30)      Alice 2020-01-22 14:01:05  \n",
       "1  (40, 50, 60)        Bob 2020-01-23 14:01:05  \n",
       "2  (70, 80, 90)    Charlee 2020-01-24 14:01:05  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas = complex_data_df.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------+-----------+---------+------------+----------+-------------------+\n",
      "|col_bool|            col_dict|col_float|col_integer| col_list|     col_row|col_string|           col_time|\n",
      "+--------+--------------------+---------+-----------+---------+------------+----------+-------------------+\n",
      "|    true|           [k1 -> 0]|     1.44|         10|[1, 2, 3]|[10, 20, 30]|     Alice|2020-01-22 14:01:05|\n",
      "|    true|  [k1 -> 0, k2 -> 1]|     2.44|         20|[4, 5, 6]|[40, 50, 60]|       Bob|2020-01-23 14:01:05|\n",
      "|   false|[k3 -> 2, k1 -> 0...|     3.44|         30|[7, 8, 9]|[70, 80, 90]|   Charlee|2020-01-24 14:01:05|\n",
      "+--------+--------------------+---------+-----------+---------+------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = sqlContext.createDataFrame(df_pandas).show()\n",
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
